{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38264bittestneurolcondac67eea37cb1c413eb235bd2784aecf63",
   "display_name": "Python 3.8.2 64-bit ('test_neurol': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy BCI using `neurol`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show how to create a dummy Brain-Computer Interface using `neurol`. This excercise should hopefully give a basic idea of the workflow of creating a BCI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the `generic_BCI` class\n",
    "from neurol.BCI import generic_BCI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's print some documentation to see what we have available to us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on class generic_BCI in module neurol.BCI:\n\nclass generic_BCI(builtins.object)\n |  generic_BCI(classifier, transformer=None, action=<built-in function print>, calibrator=None)\n |  \n |  Implements a generic Brain-Computer Interface.\n |  \n |  Internally manages a buffer of the signal given in `stream` and\n |  continuously performs classification on appropriately transformed\n |  real-time neural data. At each classification, a corresponding `action`\n |  is performed.\n |  \n |  Attributes:\n |      classifier: a function which performs classification on the\n |          most recent data (transformed as needed). returns classification.\n |      transformer: function which takes in the most recent data (`buffer`)\n |          and returns the transformed input the classifer expects.\n |      action: a function which takes in the classification, and\n |          performs some action.\n |      calibrator: a function which is run on startup to perform\n |          calibration using `stream`; returns `calibration_info`\n |          which is used by `classifier` and `transformer`.\n |      calibration_info: the result of the calibrator, if applicable.\n |      buffer_length(int): the length of the `buffer`; specifies the\n |          number of samples of the signal to keep for classification.\n |      brain_state: the most recent brain state classification.\n |  \n |  Methods defined here:\n |  \n |  __init__(self, classifier, transformer=None, action=<built-in function print>, calibrator=None)\n |      Initialize a generic BCI object.\n |      \n |      See class documentation for infromation about the class itself.\n |      \n |      Arguments:\n |          classifier: a function which performs classification on the\n |              most recent data (transformed as needed). returns class.\n |          transformer: function which takes in the most recent data (`buffer`)\n |              and returns the transformed input the classifer expects.\n |          action: a function which takes in the classification, and\n |              performs some action.\n |          calibrator: a function which is run on startup to perform\n |              calibration using `stream`; returns `calibration_info`\n |              which is used by `classifier` and `transformer`.\n |  \n |  calibrate(self, stream)\n |      runs the `calibrator`.\n |      \n |      return value of `calibrator` is stored in the object's\n |      `calibration_info` which the `transformer` and `classifier`\n |      can use at run-time of BCI.\n |      \n |      Arguments:\n |          stream(neurol.streams object): neurol stream for brain data.\n |  \n |  run(self, stream)\n |      Runs the defined Brain-Computer Interface.\n |      \n |      Internally manages a buffer of the signal given in `stream` and\n |      continuously performs classification on appropriately transformed\n |      real-time neural data. At each classification, a corresponding `action`\n |      is performed.\n |      \n |      \n |      Arguments:\n |          stream(neurol.streams object): neurol stream for brain data.\n |  \n |  test_update_rate(self, stream, test_length=10, perform_action=True)\n |      Returns the rate at which the BCI is able to make a classification\n |      and perform its action.\n |      \n |      Arguments:\n |          stream(neurol.streams object): neurol stream for brain data.\n |          test_length(float): how long to run the test for in seconds.\n |          perform_action(bool): whether to perform the action or skip it.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n\n"
     ]
    }
   ],
   "source": [
    "help(generic_BCI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define an instance of `generic_BCI` we need to give it a `classifier` which decodes the given brain signal into some kind of \"brain state\". For instance, a classifier might detect whether someone is concentrating.\n",
    "\n",
    "If you'd like, you can also give it a `transformer` which transforms the internal buffer of brain data into something perhaps more useful for the classifier to classify on. For instance, if you wanted to classify using the power of alpha waves in the EEG signal, your transformer could be a function which calculates alpha wave power in the most recent second of data. By default, no transformation is performed. \n",
    "\n",
    "Finally, the classification or \"brain-state\" returned by the classifier is passed on to the `action` function of the BCI, which does something in response to the \"brain-state\". For instance, you might set it so that it turns off the lights of the classifier thinks the brain signal indicates drowsiness. By default, the action is to simply print the \"brain-state\" classification.\n",
    "\n",
    "`generic_BCI` also supports calibration. You can pass in a `calibrator` on initialization which returns an object that is made available to the `transformer` and `classifier` to modify their behaviour. For instance, you might want to measure a baseline of alpha wave power for your classifier to use when making its predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the simplest possible \"brain-computer interface\" below. It won't do anything interesting yet. We will give it a dummy classifier which always returns the same \"brain-state\" classification. We won't be doing any transformation, and our action will be to simply print out the classification. We also won't be doing any calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the dummy classifier\n",
    "def dummy_clf(clf_input, clb_info):\n",
    "    return \"Dummy Mummy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `classifier` takes in two inputs: \n",
    "\n",
    "`clf_input` is the transformed output of the `transformer`. If no transformer is given, there won't be any transformation performed and this will just be the buffer of most recent brain data streamed.\n",
    "\n",
    "`clb_info` is the calibratio information returned by the `calibrator`. If no calibrator is defined, this will always be `None`. Even if the `classifier` doesn't use the calibration, it still needs this as an argument since the BCI is expecting a particular format of functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create our dummy BCI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_bci = generic_BCI(dummy_clf, transformer=None, action=print, calibrator=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test it, we need a stream of data for our BCI to use. This could come from any number of devices. `generic_BCI` assumes a `neurol.streams` object. \n",
    "\n",
    "Here, we create a stream object for a data source that streams over lsl. The process is similar for different data sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurol.connect_device import get_lsl_EEG_inlets\n",
    "from neurol import streams\n",
    "\n",
    "inlet = get_lsl_EEG_inlets()[0] # gets first inlet, assuming only one EEG streaming device is connected\n",
    "\n",
    "# we ask the stream object to manage a buffer of 1024 samples from the inlet\n",
    "stream = streams.lsl_stream(inlet, buffer_length=1024) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the dummy BCI! We've already defined its (dummy) behaviour, and only need to give it the `inlet` to run. The way we defined the BCI, we'd expect it to continually print the classification \"Dummy Mummy\".\n",
    "\n",
    "We wrap it in a try/except block so that we can safely stop it with a keyboard interrupt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "Dummy Mummy\n",
      "\n",
      "\n",
      "QUIT BCI\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dummy_bci.run(stream)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    stream.close()\n",
    "    \n",
    "    print('\\n')\n",
    "    print('QUIT BCI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There! It does what we'd expect. Now we can move on to making it do something more interesting!"
   ]
  }
 ]
}