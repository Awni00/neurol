{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 32-bit ('venv': venv)",
   "display_name": "Python 3.8.2 32-bit ('venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "2782778a59786a4290ea2d58bbf37057eeff34d0a420e0d69215fc2ae14e5fd8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Auto-ML BCI"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "This notebook demos the usage of `automl_BCI` in `neurol.BCI`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "`automl_BCI` is a BCI class in `neurol.BCI` which trains a custom machine learning model at initialization by recording data associated with some choice of \"brain states\". After recording data for each brain state, it transforms the data using the given `transformer` and epochs the recordings. Finally, it trains the given `model` using that data and reports back the performance it achieves.\n",
    "\n",
    "After this initialization step (performed by `build_model`), the `automl_BCI` runs much like a typical `neurol.BCI`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurol.BCI import automl_BCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on class automl_BCI in module neurol.BCI:\n\nclass automl_BCI(generic_BCI)\n |  automl_BCI(model, epoch_len, n_states, transformer=None, action=<built-in function print>)\n |  \n |  Implements a Brain-Computer Interface which builds its own classifier\n |  by training a machine learning model in the calibration stage.\n |  \n |  At calibration, data is recorded for some number of brain-states\n |  then a machine-learning classifier is trained on the transformed data.\n |  \n |  Internally manages a buffer of the signal given in `stream` and\n |  continuously performs classification on appropriately transformed\n |  real-time neural data. At each classification, a corresponding `action`\n |  is performed.\n |  \n |  Attributes:\n |      model: a machine learning model.\n |      classifier: the model's predictor after training.\n |          accepts transformed data and returns classification.\n |      transformer: function which takes in the most recent data (`buffer`)\n |          and returns the transformed input the classifer expects.\n |      action: a function which takes in the classification, and\n |          performs some action.\n |      brain_state: the most recent brain state classification.\n |  \n |  Method resolution order:\n |      automl_BCI\n |      generic_BCI\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, model, epoch_len, n_states, transformer=None, action=<built-in function print>)\n |      Initialize an autoML BCI object.\n |      \n |      See class documentation for infromation about the class itself.\n |      \n |      Args:\n |          model: a model object which has fit(X, y) and predict(X) methods.\n |          epoch_len (int): the length of the epochs (in # of samples)\n |              used in training and prediction by the model.\n |          n_states (int): the number of brain states being classified.\n |          transformer (callable, optional): function which takes in the\n |              most recent data (`buffer`) and returns the transformed input\n |              the classifer expects. Defaults to None.\n |          action (callable, optional): a function which takes in the\n |              classification, and performs some action. Defaults to print.\n |  \n |  build_model(self, stream, recording_length)\n |      records brain signal\n |      \n |      Args:\n |          stream (neurol.streams object): neurol stream for brain data.\n |          recording_length (float): length in seconds for the recording of\n |              each brain state to be used for training the model.\n |  \n |  run(self, stream)\n |      Runs the defined Brain-Computer Interface.\n |      \n |      Internally manages a buffer of the signal given in `stream` and\n |      continuously performs classification on appropriately transformed\n |      real-time neural data. At each classification, a corresponding `action`\n |      is performed.\n |      \n |      \n |      Arguments:\n |          stream(neurol.streams object): neurol stream for brain data.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from generic_BCI:\n |  \n |  calibrate(self, stream)\n |      runs the `calibrator`.\n |      \n |      return value of `calibrator` is stored in the object's\n |      `calibration_info` which the `transformer` and `classifier`\n |      can use at run-time of BCI.\n |      \n |      Arguments:\n |          stream(neurol.streams object): neurol stream for brain data.\n |  \n |  test_update_rate(self, stream, test_length=10, perform_action=True)\n |      Returns the rate at which the BCI is able to make a classification\n |      and perform its action.\n |      \n |      Arguments:\n |          stream(neurol.streams object): neurol stream for brain data.\n |          test_length(float): how long to run the test for in seconds.\n |          perform_action(bool): whether to perform the action or skip it.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from generic_BCI:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n\n"
     ]
    }
   ],
   "source": [
    "help(automl_BCI)"
   ]
  },
  {
   "source": [
    "As the documentation says, an `automl_BCI` object needs to be initialized with a `model`, `epoch_len`, `n_states`. \n",
    "\n",
    "The `model` is any model object with `fit(X, y)` and `predict(X)` methods. Make sure that this type of model is compatible with the data after transformation. \n",
    "\n",
    "`epoch_len` is the desired length of epochs in # of samples. This is used when epoching to train the model, as well as when running the BCI. This is what is passed in to the transformer before being passed to the model.\n",
    "\n",
    "`n_states` is the number of brain states we are asking the model to distinguish between. Internally, the BCI identifies brain states by an index starting at zero. In `build_model`, `n_states` different recordings are made for training.\n",
    "\n",
    "Finally, an `automl_BCI` object also needs a `transformer` and an `action` (like other `neurol.BCI` objects). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define our parameters here\n",
    "epoch_len = 50 # (samples)\n",
    "recording_length = 1 # (seconds)\n",
    "n_states = 3\n",
    "\n",
    "transformer = lambda x: x[:, 0] # only use first channel\n",
    "\n",
    "from sklearn import svm\n",
    "model = svm.SVC() # support vector machine\n"
   ]
  },
  {
   "source": [
    "now we can define the `automl_BCI`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bci = automl_BCI(model, epoch_len, n_states, transformer=transformer, action=print)"
   ]
  },
  {
   "source": [
    "As always, we get our stream of data..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurol.connect_device import get_lsl_EEG_inlets\n",
    "import neurol.streams\n",
    "\n",
    "inlets = get_lsl_EEG_inlets()\n",
    "inlet = inlets[0]\n",
    "\n",
    "stream = neurol.streams.lsl_stream(inlet)"
   ]
  },
  {
   "source": [
    "Finally, we can initialize the BCI and have it build its model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recording for 1 seconds...\n",
      "Recording for 1 seconds...\n",
      "Recording for 1 seconds...\n",
      "Done! \n",
      "\n",
      "Performance on training data: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.71      0.62        17\n",
      "         1.0       0.75      0.19      0.30        16\n",
      "         2.0       0.50      0.71      0.59        17\n",
      "\n",
      "    accuracy                           0.54        50\n",
      "   macro avg       0.60      0.53      0.50        50\n",
      "weighted avg       0.60      0.54      0.50        50\n",
      "\n",
      "Performance on test data: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "         2.0       0.22      0.50      0.31         4\n",
      "\n",
      "    accuracy                           0.15        13\n",
      "   macro avg       0.07      0.17      0.10        13\n",
      "weighted avg       0.07      0.15      0.09        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bci.build_model(stream, recording_length)"
   ]
  },
  {
   "source": [
    "This process gives allows the BCI to create its own classifier. We are given the model's performance on both training data, and testing data so we can evaluate the BCI before running it.\n",
    "\n",
    "We are now ready to run the BCI. It runs exactly like a `generic_BCI`, continuously transforming and classifying the stream of data, and responding with its action."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "\n",
      "QUIT BCI\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    bci.run(stream)\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n')\n",
    "    print('QUIT BCI')"
   ]
  },
  {
   "source": [
    "That's it! What we did above was just a demo (recording length too short, epoch_len too small, trivial transformer, etc...), but it should give you an idea of how `automl_BCI` works. In practice, you need more data (longer recording length) and a more thoughtfull transformer. For a lot of applications, frequency domain information such as the powers of EEG wavebands is more predictive than the raw time-domain signal,so pick a transformer accordingly :)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}